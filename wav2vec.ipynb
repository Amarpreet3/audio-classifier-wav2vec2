{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8130934,"sourceType":"datasetVersion","datasetId":4555568},{"sourceId":8978354,"sourceType":"datasetVersion","datasetId":5406253}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:37:51.670527Z","iopub.execute_input":"2024-07-18T12:37:51.670890Z","iopub.status.idle":"2024-07-18T12:38:04.790798Z","shell.execute_reply.started":"2024-07-18T12:37:51.670859Z","shell.execute_reply":"2024-07-18T12:38:04.789749Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:38:14.954874Z","iopub.execute_input":"2024-07-18T12:38:14.955258Z","iopub.status.idle":"2024-07-18T12:38:15.233245Z","shell.execute_reply.started":"2024-07-18T12:38:14.955223Z","shell.execute_reply":"2024-07-18T12:38:15.232319Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85ade3d5adac4adbba21c4fdfa8e66c2"}},"metadata":{}}]},{"cell_type":"code","source":"%%capture\n!apt install git-lfs","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:40:51.394094Z","iopub.execute_input":"2024-07-18T12:40:51.394729Z","iopub.status.idle":"2024-07-18T12:40:54.508643Z","shell.execute_reply.started":"2024-07-18T12:40:51.394699Z","shell.execute_reply":"2024-07-18T12:40:54.507212Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\nimport librosa\nimport gc\nimport ast\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport torchaudio\nimport sys\nimport datasets\nfrom datasets import load_dataset,load_metric\nfrom transformers import AutoFeatureExtractor\nfrom transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\nimport librosa\nfrom datasets import load_from_disk\nfrom transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification, TrainingArguments, Trainer\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport numpy as np\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-18T12:41:28.167649Z","iopub.execute_input":"2024-07-18T12:41:28.168045Z","iopub.status.idle":"2024-07-18T12:41:47.935939Z","shell.execute_reply.started":"2024-07-18T12:41:28.168009Z","shell.execute_reply":"2024-07-18T12:41:47.935127Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-07-18 12:41:39.692440: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-18 12:41:39.692567: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-18 12:41:39.825093: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"model_checkpoint = \"facebook/wav2vec2-base\"\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:42:16.105179Z","iopub.execute_input":"2024-07-18T12:42:16.106271Z","iopub.status.idle":"2024-07-18T12:42:16.111071Z","shell.execute_reply.started":"2024-07-18T12:42:16.106237Z","shell.execute_reply":"2024-07-18T12:42:16.110090Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"metric = load_metric(\"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:42:20.834702Z","iopub.execute_input":"2024-07-18T12:42:20.835592Z","iopub.status.idle":"2024-07-18T12:42:21.250930Z","shell.execute_reply.started":"2024-07-18T12:42:20.835559Z","shell.execute_reply":"2024-07-18T12:42:21.250168Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2588679507.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric(\"accuracy\")\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71077c66c17241b5804aef04963334a5"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = load_dataset(\"audiofolder\", data_dir=\"/kaggle/input/the-fake-or-real-dataset/for-norm/for-norm\")","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:42:28.613527Z","iopub.execute_input":"2024-07-18T12:42:28.614025Z","iopub.status.idle":"2024-07-18T12:48:30.957689Z","shell.execute_reply.started":"2024-07-18T12:42:28.613994Z","shell.execute_reply":"2024-07-18T12:48:30.956825Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/53868 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f97e57959d0483da364f8c6760ff427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/10798 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08283ceff1a04f26a4da161faa7cf2da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/4634 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d123ca0430d24c33b4a2e19cca573de7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7974f7c978a74e9e8d6cb5b71ddc2797"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd12571330594681b8cca7818d10935a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64251ec0df6346b5872a17a17717f244"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:49:36.498395Z","iopub.execute_input":"2024-07-18T12:49:36.499139Z","iopub.status.idle":"2024-07-18T12:49:36.505913Z","shell.execute_reply.started":"2024-07-18T12:49:36.499105Z","shell.execute_reply":"2024-07-18T12:49:36.505000Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['audio', 'label'],\n        num_rows: 53868\n    })\n    validation: Dataset({\n        features: ['audio', 'label'],\n        num_rows: 10798\n    })\n    test: Dataset({\n        features: ['audio', 'label'],\n        num_rows: 4634\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the dataset\n#dataset = load_dataset(\"audiofolder\", data_dir=\"/kaggle/input/the-fake-or-real-dataset/for-norm/for-norm\")\n\n# Function to get a subset of the dataset\ndef get_subset(dataset_split, percentage):\n    split_size = len(dataset_split)\n    subset_size = int(split_size * percentage)\n    return dataset_split.shuffle(seed=42).select(range(subset_size))\n\n# Define the percentage to select\npercentage = 0.05\n\n# Get subsets for train, validation, and test splits\ntrain_subset = get_subset(dataset['train'], percentage)\nvalidation_subset = get_subset(dataset['validation'], percentage)\ntest_subset = get_subset(dataset['test'], percentage)\n\n# Create a new DatasetDict with the subsets but with the same names\nsubset_dataset = {\n    'train': train_subset,\n    'validation': validation_subset,\n    'test': test_subset\n}\n\n# Optionally, convert to DatasetDict if needed\nfrom datasets import DatasetDict\nsubset_dataset = DatasetDict(subset_dataset)\n\n# Verify the sizes\nprint(f\"Train subset size: {len(subset_dataset['train'])}\")\nprint(f\"Validation subset size: {len(subset_dataset['validation'])}\")\nprint(f\"Test subset size: {len(subset_dataset['test'])}\")\n\n# Now you can use subset_dataset for your tasks\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:49:39.748960Z","iopub.execute_input":"2024-07-18T12:49:39.749378Z","iopub.status.idle":"2024-07-18T12:49:45.685904Z","shell.execute_reply.started":"2024-07-18T12:49:39.749345Z","shell.execute_reply":"2024-07-18T12:49:45.684912Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Train subset size: 2693\nValidation subset size: 539\nTest subset size: 231\n","output_type":"stream"}]},{"cell_type":"code","source":"subset_dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:49:49.991299Z","iopub.execute_input":"2024-07-18T12:49:49.991997Z","iopub.status.idle":"2024-07-18T12:49:49.997941Z","shell.execute_reply.started":"2024-07-18T12:49:49.991963Z","shell.execute_reply":"2024-07-18T12:49:49.997058Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['audio', 'label'],\n        num_rows: 2693\n    })\n    validation: Dataset({\n        features: ['audio', 'label'],\n        num_rows: 539\n    })\n    test: Dataset({\n        features: ['audio', 'label'],\n        num_rows: 231\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset = subset_dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:49:54.711814Z","iopub.execute_input":"2024-07-18T12:49:54.712218Z","iopub.status.idle":"2024-07-18T12:49:54.716831Z","shell.execute_reply.started":"2024-07-18T12:49:54.712187Z","shell.execute_reply":"2024-07-18T12:49:54.715706Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:49:57.273622Z","iopub.execute_input":"2024-07-18T12:49:57.274412Z","iopub.status.idle":"2024-07-18T12:49:57.280230Z","shell.execute_reply.started":"2024-07-18T12:49:57.274377Z","shell.execute_reply":"2024-07-18T12:49:57.279201Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['audio', 'label'],\n        num_rows: 2693\n    })\n    validation: Dataset({\n        features: ['audio', 'label'],\n        num_rows: 539\n    })\n    test: Dataset({\n        features: ['audio', 'label'],\n        num_rows: 231\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset[\"test\"][8]","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:50:01.892571Z","iopub.execute_input":"2024-07-18T12:50:01.893260Z","iopub.status.idle":"2024-07-18T12:50:10.309191Z","shell.execute_reply.started":"2024-07-18T12:50:01.893225Z","shell.execute_reply":"2024-07-18T12:50:10.308148Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'audio': {'path': '/kaggle/input/the-fake-or-real-dataset/for-norm/for-norm/testing/fake/file2003.wav_16k.wav_norm.wav_mono.wav_silence.wav',\n  'array': array([0.03839111, 0.02700806, 0.03109741, ..., 0.05004883, 0.05895996,\n         0.06265259]),\n  'sampling_rate': 16000},\n 'label': 0}"},"metadata":{}}]},{"cell_type":"code","source":"# Print the label names\nprint(dataset[\"train\"].features[\"label\"])\n\n# Get the labels\nlabels = dataset[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = str(i)\n    id2label[str(i)] = label\n\nprint(id2label)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:50:19.831914Z","iopub.execute_input":"2024-07-18T12:50:19.832743Z","iopub.status.idle":"2024-07-18T12:50:19.839634Z","shell.execute_reply.started":"2024-07-18T12:50:19.832712Z","shell.execute_reply":"2024-07-18T12:50:19.838734Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"ClassLabel(names=['fake', 'real'], id=None)\n{'0': 'fake', '1': 'real'}\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Load the processor and model\n# processor, model = load_wav2vec_model()","metadata":{"execution":{"iopub.status.busy":"2024-07-17T20:16:12.182870Z","iopub.execute_input":"2024-07-17T20:16:12.183276Z","iopub.status.idle":"2024-07-17T20:16:12.189445Z","shell.execute_reply.started":"2024-07-17T20:16:12.183242Z","shell.execute_reply":"2024-07-17T20:16:12.188301Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"id2label","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:50:23.139023Z","iopub.execute_input":"2024-07-18T12:50:23.139402Z","iopub.status.idle":"2024-07-18T12:50:23.145541Z","shell.execute_reply.started":"2024-07-18T12:50:23.139371Z","shell.execute_reply":"2024-07-18T12:50:23.144656Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'0': 'fake', '1': 'real'}"},"metadata":{}}]},{"cell_type":"code","source":"feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)\nfeature_extractor","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:50:25.699035Z","iopub.execute_input":"2024-07-18T12:50:25.699891Z","iopub.status.idle":"2024-07-18T12:50:26.441592Z","shell.execute_reply.started":"2024-07-18T12:50:25.699858Z","shell.execute_reply":"2024-07-18T12:50:26.440629Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c942cfa10cff4906b6beff2c67f417f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.84k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2bdef88aae042bf9f4505e6c436eb86"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Wav2Vec2FeatureExtractor {\n  \"do_normalize\": true,\n  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n  \"feature_size\": 1,\n  \"padding_side\": \"right\",\n  \"padding_value\": 0.0,\n  \"return_attention_mask\": false,\n  \"sampling_rate\": 16000\n}"},"metadata":{}}]},{"cell_type":"code","source":"max_duration = 5.0  # seconds","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:50:32.594277Z","iopub.execute_input":"2024-07-18T12:50:32.594646Z","iopub.status.idle":"2024-07-18T12:50:32.598880Z","shell.execute_reply.started":"2024-07-18T12:50:32.594617Z","shell.execute_reply":"2024-07-18T12:50:32.598006Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"sampling_rate = 16000  # Example value, adjust as per your audio data\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:50:34.314254Z","iopub.execute_input":"2024-07-18T12:50:34.315124Z","iopub.status.idle":"2024-07-18T12:50:34.319011Z","shell.execute_reply.started":"2024-07-18T12:50:34.315094Z","shell.execute_reply":"2024-07-18T12:50:34.318078Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Extract phoneme features using librosa\ndef extract_phoneme_features(audio, sr):\n    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n    return np.mean(mfccs.T, axis=0)\n\n# Analyze prosody features\ndef analyze_prosody(audio, sr):\n    pitches, magnitudes = librosa.core.piptrack(y=audio, sr=sr)\n    pitch = pitches[magnitudes > np.median(magnitudes)]\n    tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)\n    rms = librosa.feature.rms(y=audio)\n    return np.array([np.mean(pitch), np.mean(tempo), np.mean(rms)])\n\n# Detect unnatural pauses\ndef detect_pauses(audio, sr):\n    silence = librosa.effects.split(y=audio, top_db=30)\n    pauses = [(silence[i][0] - silence[i-1][1]) / sr for i in range(1, len(silence))]\n    return np.array(pauses)\n\n# Extract background noise features using librosa\ndef extract_background_noise(audio, sr):\n    zcr = librosa.feature.zero_crossing_rate(y=audio)\n    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)\n    return np.array([np.mean(zcr), np.mean(spectral_centroid)])\n\n# Identify click sounds and artifacts\ndef identify_clicks_and_artifacts(audio, sr):\n    clicks = librosa.effects.clicks(times=None, frames=None, sr=sr)\n    return np.array([np.sum(clicks)])","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:50:41.468990Z","iopub.execute_input":"2024-07-18T12:50:41.469896Z","iopub.status.idle":"2024-07-18T12:50:41.480534Z","shell.execute_reply.started":"2024-07-18T12:50:41.469862Z","shell.execute_reply":"2024-07-18T12:50:41.479591Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Define the preprocessing function\ndef preprocess_function(examples):\n    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n    sampling_rate = feature_extractor.sampling_rate\n\n    # Extract Wav2Vec2 features\n    inputs = feature_extractor(\n        audio_arrays,\n        sampling_rate=sampling_rate,\n        max_length=int(sampling_rate * max_duration),\n        truncation=True,\n    )\n\n    # Extract custom features\n    phoneme_features = [extract_phoneme_features(audio, sampling_rate) for audio in audio_arrays]\n    prosody_features = [analyze_prosody(audio, sampling_rate) for audio in audio_arrays]\n    pauses = [detect_pauses(audio, sampling_rate) for audio in audio_arrays]\n    background_noise = [extract_background_noise(audio, sampling_rate) for audio in audio_arrays]\n    #clicks_and_artifacts = [identify_clicks_and_artifacts(audio, sampling_rate) for audio in audio_arrays]\n\n    # Combine all features\n    combined_features = [\n        np.concatenate((inputs[\"input_values\"][i], phoneme_features[i], prosody_features[i], pauses[i], background_noise[i]))#, clicks_and_artifacts[i]))\n        for i in range(len(audio_arrays))\n    ]\n\n    # Convert to tensor\n    inputs[\"input_values\"] = combined_features\n\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:50:51.475193Z","iopub.execute_input":"2024-07-18T12:50:51.475898Z","iopub.status.idle":"2024-07-18T12:50:51.483718Z","shell.execute_reply.started":"2024-07-18T12:50:51.475866Z","shell.execute_reply":"2024-07-18T12:50:51.482710Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# def preprocess_function(examples):\n#     audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n#     inputs = feature_extractor(\n#         audio_arrays, \n#         sampling_rate=feature_extractor.sampling_rate, \n#         max_length=int(feature_extractor.sampling_rate * max_duration), \n#         truncation=True, \n#     )\n#     return inputs","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:43:38.412414Z","iopub.execute_input":"2024-07-17T18:43:38.413272Z","iopub.status.idle":"2024-07-17T18:43:38.418931Z","shell.execute_reply.started":"2024-07-17T18:43:38.413239Z","shell.execute_reply":"2024-07-17T18:43:38.417993Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Define which causing trouble next cell \nimport librosa\nimport numpy as np\n\n# Define your sampling rate\nsampling_rate = 16000\n\n# Example: Generate clicks every 1 second\nduration = 10  # Total duration in seconds\ntimes = np.array([1.0, 2.0, 3.0])  # Clicks at 1s, 2s, and 3s\n\n# Generate clicks\nclicks = librosa.clicks(times=times, sr=sampling_rate)\n\n# 'clicks' is now a numpy array containing the audio signal with clicks\n\n# You can use 'clicks' in your further processing\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:50:58.725093Z","iopub.execute_input":"2024-07-18T12:50:58.726034Z","iopub.status.idle":"2024-07-18T12:50:58.733033Z","shell.execute_reply.started":"2024-07-18T12:50:58.725999Z","shell.execute_reply":"2024-07-18T12:50:58.732201Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"encoded_dataset = dataset.map(preprocess_function, remove_columns=[\"audio\"], batched=True)\nencoded_dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-18T12:51:01.977272Z","iopub.execute_input":"2024-07-18T12:51:01.977654Z","iopub.status.idle":"2024-07-18T12:57:09.769571Z","shell.execute_reply.started":"2024-07-18T12:51:01.977623Z","shell.execute_reply":"2024-07-18T12:57:09.768605Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2693 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00aed28d01c7425b83bfe8a12aa53af2"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n  return _methods._mean(a, axis=axis, dtype=dtype,\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/539 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ea32da961b94f05a8d0b4a8fd05eb74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/231 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82d07ed02874480488000bf73d33a897"}},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'input_values'],\n        num_rows: 2693\n    })\n    validation: Dataset({\n        features: ['label', 'input_values'],\n        num_rows: 539\n    })\n    test: Dataset({\n        features: ['label', 'input_values'],\n        num_rows: 231\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"num_labels = len(id2label)\nmodel = AutoModelForAudioClassification.from_pretrained(\n    model_checkpoint, \n    num_labels=num_labels,\n    label2id=label2id,\n    id2label=id2label,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:16:41.791312Z","iopub.execute_input":"2024-07-18T13:16:41.792527Z","iopub.status.idle":"2024-07-18T13:16:44.183618Z","shell.execute_reply.started":"2024-07-18T13:16:41.792492Z","shell.execute_reply":"2024-07-18T13:16:44.182654Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/380M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7037bb99f8c844d1b61be9abc2214409"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = model_checkpoint.split(\"/\")[-1]\n\n\nargs = TrainingArguments(\n    f\"{model_name}-finetuned-ks\",\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=batch_size,\n    gradient_accumulation_steps=4,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=5,\n    warmup_ratio=0.1,\n    logging_steps=10,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    \n)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:16:49.327820Z","iopub.execute_input":"2024-07-18T13:16:49.329041Z","iopub.status.idle":"2024-07-18T13:16:49.392263Z","shell.execute_reply.started":"2024-07-18T13:16:49.328994Z","shell.execute_reply":"2024-07-18T13:16:49.391341Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n    predictions = np.argmax(eval_pred.predictions, axis=1)\n    return metric.compute(predictions=predictions, references=eval_pred.label_ids)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:16:52.822964Z","iopub.execute_input":"2024-07-18T13:16:52.823752Z","iopub.status.idle":"2024-07-18T13:16:52.828762Z","shell.execute_reply.started":"2024-07-18T13:16:52.823722Z","shell.execute_reply":"2024-07-18T13:16:52.827543Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=encoded_dataset[\"train\"],\n    eval_dataset=encoded_dataset[\"validation\"],\n    tokenizer=feature_extractor,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:16:56.129665Z","iopub.execute_input":"2024-07-18T13:16:56.130454Z","iopub.status.idle":"2024-07-18T13:16:56.993136Z","shell.execute_reply.started":"2024-07-18T13:16:56.130420Z","shell.execute_reply":"2024-07-18T13:16:56.992315Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:19:44.648412Z","iopub.execute_input":"2024-07-18T13:19:44.648838Z","iopub.status.idle":"2024-07-18T13:40:38.297190Z","shell.execute_reply.started":"2024-07-18T13:19:44.648810Z","shell.execute_reply":"2024-07-18T13:40:38.296110Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240718_132121-brbq53ee</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/gurmkauramarpreet-tmu/huggingface/runs/brbq53ee/workspace' target=\"_blank\">unique-dragon-2</a></strong> to <a href='https://wandb.ai/gurmkauramarpreet-tmu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/gurmkauramarpreet-tmu/huggingface' target=\"_blank\">https://wandb.ai/gurmkauramarpreet-tmu/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/gurmkauramarpreet-tmu/huggingface/runs/brbq53ee/workspace' target=\"_blank\">https://wandb.ai/gurmkauramarpreet-tmu/huggingface/runs/brbq53ee/workspace</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [105/105 18:48, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>nan</td>\n      <td>0.512059</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>nan</td>\n      <td>0.512059</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>nan</td>\n      <td>0.512059</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000000</td>\n      <td>nan</td>\n      <td>0.512059</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=105, training_loss=0.09029326665969122, metrics={'train_runtime': 1252.752, 'train_samples_per_second': 10.748, 'train_steps_per_second': 0.084, 'total_flos': 6.052184111659594e+17, 'train_loss': 0.09029326665969122, 'epoch': 4.94})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:41:08.991277Z","iopub.execute_input":"2024-07-18T13:41:08.991671Z","iopub.status.idle":"2024-07-18T13:41:31.637745Z","shell.execute_reply.started":"2024-07-18T13:41:08.991637Z","shell.execute_reply":"2024-07-18T13:41:31.636841Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': nan,\n 'eval_accuracy': 0.5120593692022264,\n 'eval_runtime': 22.0813,\n 'eval_samples_per_second': 24.41,\n 'eval_steps_per_second': 0.77,\n 'epoch': 4.94}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:51:14.665530Z","iopub.execute_input":"2024-07-18T13:51:14.665950Z","iopub.status.idle":"2024-07-18T13:51:15.185377Z","shell.execute_reply.started":"2024-07-18T13:51:14.665920Z","shell.execute_reply":"2024-07-18T13:51:15.182827Z"},"trusted":true},"execution_count":37,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/api/repos/create","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:3360\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3360\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:367\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    361\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you are trying to create or update content,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure you have a token with the `write` role.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n","\u001b[0;31mHfHubHTTPError\u001b[0m:  (Request ID: Root=1-66991dd2-000582f3713816a76c20d4fb;cc9ae645-a926-4f8a-b8a4-d1f47513a6ad)\n\n403 Forbidden: You don't have the rights to create a model under the namespace \"amarpreetkaur\".\nCannot access content at: https://huggingface.co/api/repos/create.\nIf you are trying to create or update content,make sure you have a token with the `write` role.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/api/models/wav2vec2-base-finetuned-ks","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3997\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   3995\u001b[0m \u001b[38;5;66;03m# In case the user calls this method with args.push_to_hub = False\u001b[39;00m\n\u001b[1;32m   3996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhub_model_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3997\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_hf_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3999\u001b[0m \u001b[38;5;66;03m# Needs to be executed on all processes for TPU training, but will only save on the processed determined by\u001b[39;00m\n\u001b[1;32m   4000\u001b[0m \u001b[38;5;66;03m# self.args.should_save.\u001b[39;00m\n\u001b[1;32m   4001\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(_internal_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3830\u001b[0m, in \u001b[0;36mTrainer.init_hf_repo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3827\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3828\u001b[0m     repo_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mhub_model_id\n\u001b[0;32m-> 3830\u001b[0m repo_url \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub_private_repo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3831\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhub_model_id \u001b[38;5;241m=\u001b[39m repo_url\u001b[38;5;241m.\u001b[39mrepo_id\n\u001b[1;32m   3832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush_in_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:3368\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m exist_ok \u001b[38;5;129;01mand\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m   3366\u001b[0m     \u001b[38;5;66;03m# No write permission on the namespace but repo might already exist\u001b[39;00m\n\u001b[1;32m   3367\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3368\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3369\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m repo_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m repo_type \u001b[38;5;241m==\u001b[39m REPO_TYPE_MODEL:\n\u001b[1;32m   3370\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m RepoUrl(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2418\u001b[0m, in \u001b[0;36mHfApi.repo_info\u001b[0;34m(self, repo_id, revision, repo_type, timeout, files_metadata, token)\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported repo type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2424\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2228\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[0;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[1;32m   2226\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m-> 2228\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2229\u001b[0m data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m   2230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:352\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    334\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;66;03m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;66;03m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n\u001b[1;32m    344\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m     )\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m    355\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m     )\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-66991dd2-6db96cc564c83d420d56645b;9fba4c9e-8344-45f4-9a7d-40e1a520f154)\n\nRepository Not Found for url: https://huggingface.co/api/models/wav2vec2-base-finetuned-ks.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated."],"ename":"RepositoryNotFoundError","evalue":"404 Client Error. (Request ID: Root=1-66991dd2-6db96cc564c83d420d56645b;9fba4c9e-8344-45f4-9a7d-40e1a520f154)\n\nRepository Not Found for url: https://huggingface.co/api/models/wav2vec2-base-finetuned-ks.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.","output_type":"error"}]},{"cell_type":"code","source":"trainer.predict(encoded_dataset[\"test\"])","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:42:20.784608Z","iopub.execute_input":"2024-07-18T13:42:20.785395Z","iopub.status.idle":"2024-07-18T13:42:28.727960Z","shell.execute_reply.started":"2024-07-18T13:42:20.785359Z","shell.execute_reply":"2024-07-18T13:42:28.726714Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan],\n       [nan, nan]], dtype=float32), label_ids=array([0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n       1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n       0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1]), metrics={'test_loss': nan, 'test_accuracy': 0.4935064935064935, 'test_runtime': 7.4255, 'test_samples_per_second': 31.109, 'test_steps_per_second': 1.077})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport librosa\nfrom transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n\n\n# Load the fine-tuned model and feature extractor\nmodel_name = \"motheecreator/wav2vec2-base-finetuned-ks\"  # Replace with your model's name\nmodel = AutoModelForAudioClassification.from_pretrained(model_name)\nfeature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Function to preprocess a single audio file\ndef preprocess_audio(file_path, feature_extractor, sampling_rate=16000, max_length=16000):\n    # Load the audio file\n    audio, sr = librosa.load(file_path, sr=sampling_rate)\n    \n    # Ensure the audio is the correct length\n    if len(audio) > max_length:\n        audio = audio[:max_length]  # Truncate if necessary\n    else:\n        audio = np.pad(audio, (0, max_length - len(audio)))  # Pad if necessary\n    \n    # Convert audio to the format expected by the model\n    inputs = feature_extractor(\n        audio,\n        sampling_rate=sampling_rate,\n        padding=\"max_length\",\n        max_length=max_length,\n        return_tensors=\"pt\",\n        truncation=True\n    )\n    return inputs\n\ndef predict_audio(file_path, model, feature_extractor, id2label):\n    # Preprocess the audio file\n    inputs = preprocess_audio(file_path, feature_extractor)\n    \n    # Perform inference\n    with torch.no_grad():\n        outputs = model(**inputs).logits\n        predicted_ids = torch.argmax(outputs, dim=-1).item()\n    \n    # Convert predicted ID to string for dictionary lookup\n    predicted_id_str = str(predicted_ids)\n    \n    # Check if the predicted ID is in id2label\n    if predicted_id_str in id2label:\n        prediction = id2label[predicted_id_str]\n    else:\n        prediction = \"Unknown label\"\n    \n    return prediction\n\n# Perform prediction on the single audio file\nfile_path = \"/kaggle/input/the-fake-or-real-dataset/for-original/for-original/testing/real/file1004.wav\"\nprediction = predict_audio(file_path, model, feature_extractor, id2label)\nprint(f\"The audio file is classified as: {prediction}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:51:54.604196Z","iopub.execute_input":"2024-07-18T13:51:54.605074Z","iopub.status.idle":"2024-07-18T13:51:57.279749Z","shell.execute_reply.started":"2024-07-18T13:51:54.605039Z","shell.execute_reply":"2024-07-18T13:51:57.278747Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d14a735754c540da9cbf05798d2548a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"215148d264be47daac5e80bc03b20c67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da0d772f13514595b12e07a94ed2b022"}},"metadata":{}},{"name":"stdout","text":"The audio file is classified as: real\n","output_type":"stream"}]},{"cell_type":"code","source":"# Perform prediction on the single audio file\nfile_path = \"/kaggle/input/trebble/1714316769340.wav\"\nprediction = predict_audio(file_path, model, feature_extractor, id2label)\nprint(f\"The audio file is classified as: {prediction}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:52:02.683544Z","iopub.execute_input":"2024-07-18T13:52:02.683943Z","iopub.status.idle":"2024-07-18T13:52:02.952436Z","shell.execute_reply.started":"2024-07-18T13:52:02.683909Z","shell.execute_reply":"2024-07-18T13:52:02.950136Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"The audio file is classified as: real\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}